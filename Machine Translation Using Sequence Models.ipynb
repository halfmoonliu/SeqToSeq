{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "39484736",
   "metadata": {},
   "source": [
    "## Machine Translation\n",
    "The application of sequence-to-sequence model and transformers have greatly enhanced the results of machine translation. In this project, I will walk through the steps needed to train a machine translation model using sequence-to-sequence model and tranformer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e2e5e50b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#imprt libraries\n",
    "from __future__ import unicode_literals, print_function, division\n",
    "from io import open\n",
    "import unicodedata\n",
    "import math\n",
    "import re\n",
    "import random\n",
    "import string\n",
    "import time\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c15bd0a0",
   "metadata": {},
   "source": [
    "## Dataset: English-French Sentence Pair\n",
    "The data set used in this project comes from Tatoeba (https://tatoeba.org/en), a website where people can upload sentences in any languages and contribute thier own versions of translations in other languages. The English-French dataset used here was downloaded from https://www.manythings.org/anki/, where they preprocessed the Tatoeba dataset so that it became a text file of English Frence sentence pair. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6dc645b",
   "metadata": {},
   "source": [
    "## Prepare data: Load file\n",
    "The sentence pair is saved in datapath as a .txt file. The following function ingests the files and make them into pairs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "72c60c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "def readData(lang1, lang2, dataPath, reverse = False):\n",
    "    print(\"Reading dataset...\")\n",
    "    \n",
    "    #open the file and split by lines (\\n)\n",
    "    lines = open(dataPath, encoding = 'utf-8').read().strip().split('\\n')\n",
    "    \n",
    "    #split lines into pairs (separated by tab, or \\t) and normalize\n",
    "    \n",
    "    pairs = [[cleanString(s) for s in l.split('\\t')] for l in lines]\n",
    "    \n",
    "    # Reverse if spesified\n",
    "    \n",
    "    if reverse:\n",
    "        pairs = [list(reversed(p)) for p in pairs]\n",
    "        source_lang = LangDict(lang2)\n",
    "        target_lang = LangDict(lang1)\n",
    "    else:\n",
    "        source_lang = LangDict(lang1)\n",
    "        target_lang = LangDict(lang2)\n",
    "    \n",
    "    return source_lang, target_lang, pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6382f147",
   "metadata": {},
   "source": [
    "## Preprocessing: Create Token-Index Dictionary \n",
    "When building neural netword models, it is common practice to map words to a number because models can only \"understand\" numbers\". The following LangDict class is used to walk through the wholde dataset and create word-number mapping dictionary and word count dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f693ab6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "SOS_token = 0\n",
    "EOS_token =1\n",
    "\n",
    "class LangDict:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.word2index = {}\n",
    "        self.word2count = {}\n",
    "        self.index2word = {0:\"SOS\", 1:\"EOS\"}\n",
    "        self.n_words = 2 # SOS + COS = 2\n",
    "\n",
    "    def addSentence(self, sentence):\n",
    "        for word in sentence.split(' '):\n",
    "            self.addWord(word)\n",
    "            \n",
    "    def addWord(self, word):\n",
    "        if word not in self.word2index:\n",
    "            self.word2index[word] = self.n_words\n",
    "            self.word2count[word] = 1\n",
    "            self.index2word[self.n_words] = word\n",
    "            self.n_words += 1\n",
    "        else:\n",
    "            self.word2count[word] += 1\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "428e8864",
   "metadata": {},
   "source": [
    "The following functions are used for preprocessing data (e.g. convert text to lowercase, remove puctuations)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2cb58e12",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Helper functions\n",
    "\n",
    "def unicodeToAscii(s):\n",
    "    return ''.join(\n",
    "        c for c in unicodedata.normalize('NFD', s)\n",
    "        if unicodedata.category(c) != 'Mn'\n",
    "    )\n",
    "\n",
    "def cleanString(s):\n",
    "    #transform letters to lower case ones and remove non-letter symbols\n",
    "    s = unicodeToAscii(s.lower().strip())\n",
    "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
    "    s = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", s)\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f7582904",
   "metadata": {},
   "outputs": [],
   "source": [
    "Max_length = 10\n",
    "\n",
    "exn_prefix = (\"i am\", \"i m\",\n",
    "              \"he is\", \"he s\",\n",
    "              \"she is\", \"she s\",\n",
    "              \"you are\", \"you re\",\n",
    "              \"we are\", \"we re\",\n",
    "              \"they are\", \"they re\"              \n",
    "             )\n",
    "\n",
    "def filterPair(p):\n",
    "    p1_tok = p[0].split(' ')\n",
    "    p2_tok = p[1].split(' ')\n",
    "    \n",
    "    if len(p1_tok) < Max_length and len(p2_tok) < Max_length:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "def BuildfilterdPairs(pairs):\n",
    "    pairList = list()\n",
    "    for pair in pairs:\n",
    "        if filterPair(pair)==True:\n",
    "            pairList.append([pair[0], pair[1]])\n",
    "    return pairList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2b8be260",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading dataset...\n",
      "Read 192341 sentence pairs\n",
      "Trimmed to 136657 sentence pairs\n",
      "Counting words...\n",
      "Counted words:\n",
      "eng 11820\n",
      "fra 19411\n",
      "Below is an example of sentence pair:\n",
      "['i ve been working here for several years .', 'je travaille ici depuis plusieurs annees .']\n"
     ]
    }
   ],
   "source": [
    "def prepareData(lang1, lang2, reverse = False):\n",
    "    dataPath = r'./data/eng-fra.txt'\n",
    "    input_lang, output_lang, pairs = readData(lang1, lang2, dataPath, reverse)\n",
    "    print(\"Read %s sentence pairs\" % len(pairs))\n",
    "    pairs = BuildfilterdPairs(pairs)\n",
    "    print(\"Trimmed to %s sentence pairs\" % len(pairs))\n",
    "    print(\"Counting words...\")\n",
    "    for pair in pairs:\n",
    "        input_lang.addSentence(pair[0])\n",
    "        output_lang.addSentence(pair[1])\n",
    "    print(\"Counted words:\")\n",
    "    print(input_lang.name, input_lang.n_words)\n",
    "    print(output_lang.name, output_lang.n_words)\n",
    "    \n",
    "    return input_lang, output_lang, pairs\n",
    "\n",
    "input_lang, output_lang, pairs = prepareData('eng', 'fra', False)\n",
    "\n",
    "print(\"Below is an example of sentence pair:\")\n",
    "print(random.choice(pairs))        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a4683d1",
   "metadata": {},
   "source": [
    "## Encoder Setup\n",
    "Here we define the structure of the first sequence model, the encoder, which encodes the information of the sentence in the source language. The encoder outputs a fixed length embedding, which will serve as the input of the second sequence model, the decoder, to output prediction of word in target language. The type of layer in the sequence model family used for the encoder is to be choosed. Here, I put the GRU (gated recurrent unit) for demonstration purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cf55badf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        \n",
    "        \n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
    "    \n",
    "    def forward(self, input, hidden):\n",
    "        embedded = self.embedding(input).view(1, 1, -1)\n",
    "        output = embedded\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        return output, hidden\n",
    "    \n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device = device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4059f3e2",
   "metadata": {},
   "source": [
    "## Decoder Setup\n",
    "In the original encoder-decoder setting, the decoder takes the hidden layer of the encoder as input to generate  sentence word by work in the target language. We will define the encoder without attention first and with attention later to compare performances between the two."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f0746e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size):\n",
    "        super(DecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        \n",
    "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "        self.softmax = nn.LogSoftmax(dim =1)\n",
    "\n",
    "    \n",
    "    def forward(self, x, hidden, cell):\n",
    "        output = self.embedding(input).view(1, 1, -1)\n",
    "        output = F.relu(output)\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        output = self.softmax(self.out(output[0]))\n",
    "        return output, hidden\n",
    "    \n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device = device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8a29f129",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttnDecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size, dropout_p = 0.1, max_length = Max_length):\n",
    "        super(AttnDecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.dropout_p = dropout_p\n",
    "        self.max_length = max_length\n",
    "        \n",
    "        self.embedding = nn.Embedding(self.output_size, self.hidden_size)\n",
    "        self.attn = nn.Linear(self.hidden_size*2, self.max_length)\n",
    "        self.attn_combine = nn.Linear(self.hidden_size*2, self.hidden_size)\n",
    "        self.dropout = nn.Dropout(self.dropout_p)\n",
    "        self.gru = nn.GRU(self.hidden_size, self.hidden_size)\n",
    "        self.out = nn.Linear(self.hidden_size, self.output_size)\n",
    "        \n",
    "    def forward(self, input, hidden, encoder_outputs):\n",
    "        embedded = self.embedding(input).view(1, 1, -1)\n",
    "        embedded = self.dropout(embedded)\n",
    "        \n",
    "        attn_weights = F.softmax(self.attn(torch.cat((embedded[0], hidden[0]), 1)), dim=1)\n",
    "        attn_applied = torch.bmm(attn_weights.unsqueeze(0), encoder_outputs.unsqueeze(0))\n",
    "        \n",
    "        output = torch.cat((embedded[0], attn_applied[0]), 1)\n",
    "        output = self.attn_combine(output).unsqueeze(0)\n",
    "        \n",
    "        output = F.relu(output)\n",
    "        ourput, hidden = self.gru(output, hidden)\n",
    "        \n",
    "        output = F.log_softmax(self.out(output[0]), dim =1)\n",
    "        \n",
    "        return output, hidden, attn_weights\n",
    "\n",
    "    \n",
    "    def init_hidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device = device)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c4743380",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define helper functions\n",
    "def indexFromSentence(lang, sentence):\n",
    "    return [lang.word2index[word]  for word in sentence.split(' ')]\n",
    "\n",
    "def tensorFromSentence(lang, sentence):\n",
    "    indexes = indexFromSentence(lang, sentence)\n",
    "    indexes.append(EOS_token)\n",
    "    return torch.tensor(indexes, dtype = torch.long, device = device).view(-1, 1)\n",
    "\n",
    "def tensorsFromPair(pair):\n",
    "    input_tensor = tensorFromSentence(input_lang, pair[0])\n",
    "    target_tensor = tensorFromSentence(output_lang, pair[1])\n",
    "    return (input_tensor, target_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03522232",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c9bc8f9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#one training iteration\n",
    "def train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, \n",
    "         decoder_optimizer, criterion, max_length = Max_length):\n",
    "    \n",
    "    #initialize encoder hidden layer weights\n",
    "    encoder_hidden = encoder.initHidden()\n",
    "    \n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "    \n",
    "    input_length = input_tensor.size(0)\n",
    "    target_length = target_tensor.size(0)\n",
    "    \n",
    "    encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device = device)\n",
    "    \n",
    "    loss = 0\n",
    "    \n",
    "    #encoder\n",
    "    \n",
    "    for ei in range(input_length):\n",
    "        encoder_output, encoder_hidden = encoder(input_tensor[ei], encoder_hidden)\n",
    "        encoder_outputs[ei] = encoder_output[0, 0]\n",
    "    \n",
    "    decoder_input = torch.tensor([[SOS_token]], device=device)\n",
    "    decoder_hidden = encoder_hidden\n",
    "    \n",
    "    #decoder\n",
    "    for di in range(target_length):\n",
    "        decoder_output, decoder_hidden, decoderattention = decoder(decoder_input, decoder_hidden, encoder_outputs)\n",
    "        \n",
    "        \n",
    "        topv, topi = decoder_output.topk(1)\n",
    "        decoder_input = topi.squeeze().detach()\n",
    "        \n",
    "        loss += criterion(decoder_output, target_tensor[di])\n",
    "        \n",
    "        if decoder_input.item() == EOS_token:\n",
    "            break;\n",
    "    \n",
    "    loss.backward()\n",
    "    \n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "    \n",
    "    return loss.item() / target_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "44263330",
   "metadata": {},
   "outputs": [],
   "source": [
    "#helper function: timers\n",
    "\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s/ 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m,s)\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a3de189f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n        if iter % plot_every ==0:\\n            plot_loss_avg = plot_loss_total/ plot_every\\n            plot_losses.append(plot_loss_avg)\\n            plot_loss_total = 0\\n            \\n        showPlot(plot_losses)\\n'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#iterate over training process\n",
    "def trainIters(encoder, decoder, n_iters, print_every=1000, plot_every = 100, learning_rate = 0.01):\n",
    "    \n",
    "    start = time.time()\n",
    "    plot_losses = []\n",
    "    print_loss_total = 0\n",
    "    plot_loss_total = 0\n",
    "    \n",
    "    encoder_optimizer = optim.SGD(encoder.parameters(), lr = learning_rate)\n",
    "    decoder_optimizer = optim.SGD(decoder.parameters(), lr = learning_rate)\n",
    "    training_pairs = [tensorsFromPair(random.choice(pairs))\n",
    "                     for i in range(n_iters)]\n",
    "\n",
    "    criterion = nn.NLLLoss()\n",
    "    \n",
    "    for iter in range(1, n_iters + 1):\n",
    "        \n",
    "        training_pair = training_pairs[iter - 1]\n",
    "        input_tensor = training_pair[0]\n",
    "        target_tensor = training_pair[1]\n",
    "        \n",
    "        loss = train(input_tensor, target_tensor, encoder,\n",
    "                    decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
    "        \n",
    "        print_loss_total += loss\n",
    "        plot_loss_total += loss\n",
    "        \n",
    "        if iter % print_every == 0:\n",
    "            print_loss_avg = print_loss_total / print_every\n",
    "            print_loss_total = 0\n",
    "            print('%s (%d %d%%) %.4f' % (timeSince(start, iter/ n_iters), \n",
    "                                         iter, iter/ n_iters  *  100, print_loss_avg))\n",
    "'''\n",
    "        if iter % plot_every ==0:\n",
    "            plot_loss_avg = plot_loss_total/ plot_every\n",
    "            plot_losses.append(plot_loss_avg)\n",
    "            plot_loss_total = 0\n",
    "            \n",
    "        showPlot(plot_losses)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "01d01fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot resutls\n",
    "import matplotlib.pyplot as plt\n",
    "plt.switch_backend('agg')\n",
    "\n",
    "import matplotlib.ticker as ticker\n",
    "import numpy as np\n",
    "\n",
    "def showPlot(points):\n",
    "    plt.figure()\n",
    "    fig, ax = plt.subplots()\n",
    "    #ticks at regular inter\n",
    "    loc = ticker.MultipleLocator(base= 0.2)\n",
    "    ax.yaxis.set_major_locator(loc)\n",
    "    plt.plot(points)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9cac0a2",
   "metadata": {},
   "source": [
    "## Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "596c3373",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(encoder, decoder, sentence, max_length=Max_length):\n",
    "    with torch.no_grad():\n",
    "        input_tensor = tensorFromSentence(input_lang, sentence)\n",
    "        input_length = input_tensor.size()[0]\n",
    "        encoder_hidden = encoder.initHidden()\n",
    "        \n",
    "        encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device = device)\n",
    "        for ei in range(input_length):\n",
    "\n",
    "            encoder_output, encoder_hidden = encoder(input_tensor[ei], encoder_hidden)\n",
    "            encoder_outputs[ei] = encoder_output[0, 0]\n",
    "            \n",
    "            \n",
    "        decoder_input = torch.tensor([[SOS_token]], device = device)#Start of sentens(SOS)\n",
    "        \n",
    "        decoder_hidden  = encoder_hidden\n",
    "        \n",
    "        decoded_words = []\n",
    "        decoder_attentions = torch.zeros(max_length, max_length)\n",
    "        \n",
    "        for di in range(max_length):\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(decoder_input, decoder_hidden, encoder_outputs)\n",
    "            topv, topi, = decoder_output.data.topk(1)\n",
    "            \n",
    "            if topi.item() == EOS_token:\n",
    "                decoded_words.append('<EOS>')\n",
    "                break;\n",
    "            else:\n",
    "                decoded_words.append(output_lang.index2word[topi.item()])\n",
    "            \n",
    "            decoder_input = topi.squeeze().detach()\n",
    "        \n",
    "        return decoded_words, decoder_attentions[:di + 1]\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7626a0ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13m 24s (- 120m 37s) (5000 10%) 3.7257\n",
      "27m 56s (- 111m 46s) (10000 20%) 3.7071\n",
      "43m 12s (- 100m 50s) (15000 30%) 3.6455\n",
      "57m 41s (- 86m 31s) (20000 40%) 3.6230\n",
      "72m 13s (- 72m 13s) (25000 50%) 3.5851\n",
      "86m 36s (- 57m 44s) (30000 60%) 3.5210\n",
      "101m 2s (- 43m 18s) (35000 70%) 3.4808\n",
      "115m 34s (- 28m 53s) (40000 80%) 3.4384\n",
      "130m 5s (- 14m 27s) (45000 90%) 3.4031\n",
      "144m 41s (- 0m 0s) (50000 100%) 3.3612\n"
     ]
    }
   ],
   "source": [
    "\n",
    "hidden_size = 256\n",
    "encoder1 = EncoderRNN(input_lang.n_words, hidden_size).to(device)\n",
    "atten_decoder1 = AttnDecoderRNN(hidden_size, output_lang.n_words, dropout_p=0.1).to(device)\n",
    "\n",
    "trainIters(encoder1, atten_decoder1, 50000, print_every=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f64eb691",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluateRandomly(encoder, decoder, n = 10):\n",
    "    for i in range(n):\n",
    "        pair = random.choice(pairs)\n",
    "        print('Sentence from source language: ', pair[0])\n",
    "        output_words, attentions = evaluate(encoder, decoder, pair[0])\n",
    "        output_sentence = ' '.join(output_words)\n",
    "        print('Model generated sentence: ', output_sentence)\n",
    "        print('Sentence from target language: ', pair[1])\n",
    "        print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62397de2",
   "metadata": {},
   "source": [
    "## Examples of tranlation produced by current model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "559ecd35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence from source language:  doing that would be stupid .\n",
      "Model generated sentence:  a ca serait a . . . . . .\n",
      "Sentence from target language:  faire cela serait stupide .\n",
      "\n",
      "Sentence from source language:  come in .\n",
      "Model generated sentence:  viens dans . <EOS>\n",
      "Sentence from target language:  entre .\n",
      "\n",
      "Sentence from source language:  how did the exam go ?\n",
      "Model generated sentence:  comment as le . <EOS>\n",
      "Sentence from target language:  comment s est passe l examen ?\n",
      "\n",
      "Sentence from source language:  you re not dead .\n",
      "Model generated sentence:  tu ne es pas . . . . . .\n",
      "Sentence from target language:  vous n etes pas mort .\n",
      "\n",
      "Sentence from source language:  the contract was signed .\n",
      "Model generated sentence:  les homme etait etait . <EOS>\n",
      "Sentence from target language:  le contrat a ete conclu .\n",
      "\n",
      "Sentence from source language:  raise your hand if you know the answer .\n",
      "Model generated sentence:  la <EOS>\n",
      "Sentence from target language:  levez la main si vous connaissez la reponse .\n",
      "\n",
      "Sentence from source language:  tom worked all day .\n",
      "Model generated sentence:  tom a a a . . . . . .\n",
      "Sentence from target language:  tom a travaille toute la journee .\n",
      "\n",
      "Sentence from source language:  saddle my horse .\n",
      "Model generated sentence:  l mon vie a . <EOS>\n",
      "Sentence from target language:  sellez mon cheval .\n",
      "\n",
      "Sentence from source language:  i ll call them .\n",
      "Model generated sentence:  je t de . . <EOS>\n",
      "Sentence from target language:  je les appellerai .\n",
      "\n",
      "Sentence from source language:  we re related .\n",
      "Model generated sentence:  nous sommes a . . <EOS>\n",
      "Sentence from target language:  nous sommes de la meme famille .\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluateRandomly(encoder1, atten_decoder1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6637d983",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "1. [NLP FROM SCRATCH: TRANSLATION WITH A SEQUENCE TO SEQUENCE NETWORK AND ATTENTION](https://pytorch.org/tutorials/intermediate/seq2seq_translation_tutorial.html), PyTorch tutorial by Sean  Robertson.\n",
    "2. [Aladdin Persson's Github](https://github.com/aladdinpersson)\n",
    "3. Kyunghyun Cho, Bart van Merrienboer, Caglar Gulcehre, Fethi Bougares, Holger Schwenk, and Yoshua Bengio. Learning phrase representations using rnn encoder-decoder for statistical machine translation. CoRR, abs/1406.1078, 2014.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c935a81d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
