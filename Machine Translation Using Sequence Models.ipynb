{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "39484736",
   "metadata": {},
   "source": [
    "## Machine Translation\n",
    "The application of sequence-to-sequence model and transformers have greatly enhanced the results of machine translation. In this project, I will walk through the steps needed to train a machine translation model using sequence-to-sequence model and tranformer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e2e5e50b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#imprt libraries\n",
    "from __future__ import unicode_literals, print_function, division\n",
    "from io import open\n",
    "import unicodedata\n",
    "import string\n",
    "import re\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c15bd0a0",
   "metadata": {},
   "source": [
    "## Dataset: English-French Sentence Pair\n",
    "The data set used in this project comes from Tatoeba (https://tatoeba.org/en), a website where people can upload sentences in any languages and contribute thier own versions of translations in other languages. The English-French dataset used here was downloaded from https://www.manythings.org/anki/, where they preprocessed the Tatoeba dataset so that it became a text file of English Frence sentence pair. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6dc645b",
   "metadata": {},
   "source": [
    "## Prepare data: Load file\n",
    "The sentence pair is saved in datapath as a .txt file. The following function ingests the files and make them into pairs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "72c60c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "def readData(lan1, lang2, dataPath, reverse = False):\n",
    "    print(\"Reading dataset...\")\n",
    "    \n",
    "    #open the file and split by lines (\\n)\n",
    "    lines = open(dataPath, encoding = 'utf-8').read().strip().split('\\n')\n",
    "    \n",
    "    #split lines into pairs (separated by tab, or \\t) and normalize\n",
    "    \n",
    "    pairs = [[normalizeString(s) for s in l.split('\\t')] for l in lines]\n",
    "    \n",
    "    # Reverse if spesified\n",
    "    \n",
    "    if reverse:\n",
    "        pairs = [list(reversed(p)) for p in pairs]\n",
    "        source_lang = Lang(lang2)\n",
    "        target_lang = Lang(lang1)\n",
    "    else:\n",
    "        source_lang = Lang(lang1)\n",
    "        target_lang = Lang(lang2)\n",
    "    \n",
    "    return source_lang, target_lang, pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6637d983",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "1. [NLP FROM SCRATCH: TRANSLATION WITH A SEQUENCE TO SEQUENCE NETWORK AND ATTENTION](https://pytorch.org/tutorials/intermediate/seq2seq_translation_tutorial.html), PyTorch tutorial by Sean  Robertson.\n",
    "2. Kyunghyun Cho, Bart van Merrienboer, Caglar Gulcehre, Fethi Bougares, Holger Schwenk, and Yoshua Bengio. Learning phrase representations using rnn encoder-decoder for statistical machine translation. CoRR, abs/1406.1078, 2014.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f9fe469",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
